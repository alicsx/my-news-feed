import google.generativeai as genai
import os
import re
import time
import json
import logging
import pandas as pd
import pandas_ta as ta
import requests
from datetime import datetime, timedelta, UTC
import aiohttp
import asyncio
from typing import Dict, List, Optional, Tuple
import concurrent.futures
from groq import Groq  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Groq

# =================================================================================
# --- Ø¨Ø®Ø´ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ---
# =================================================================================

# Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API
google_api_key = os.getenv("GOOGLE_API_KEY")
TWELVEDATA_API_KEY = os.getenv("TWELVEDATA_API_KEY")
CLOUDFLARE_AI_API_KEY = os.getenv("CLOUDFLARE_AI_API_KEY")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not all([google_api_key, TWELVEDATA_API_KEY]):
    raise ValueError("Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯: GOOGLE_API_KEY, TWELVEDATA_API_KEY")

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ Ø³ÛŒØ³ØªÙ…
HIGH_TIMEFRAME = "4h"
LOW_TIMEFRAME = "1h"
CANDLES_TO_FETCH = 300
CURRENCY_PAIRS_TO_ANALYZE = [
    "EUR/USD", "GBP/USD", "USD/JPY", "USD/CHF", "AUD/USD",
    "GBP/JPY", "EUR/JPY", "AUD/JPY", "NZD/USD", "USD/CAD",
    "EUR/GBP", "AUD/NZD", "EUR/AUD", "GBP/CHF", "CAD/JPY"
]

CACHE_FILE = "signal_cache.json"
CACHE_DURATION_HOURS = 2
LOG_FILE = "trading_log.log"

# Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI
GEMINI_MODEL = 'gemini-2.5-flash'
CLOUDFLARE_MODELS = [
    "@cf/meta/llama-4-scout-17b-16e-instruct",
    "@cf/deepseek-ai/deepseek-ai/deepseek-r1-distill-qwen-32b"
]
GROQ_MODELS = [
    "mixtral-8x7b-32768",
    "gemma2-9b-it"  # Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ùˆ Ù‚ÙˆÛŒâ€ŒØªØ±ÛŒÙ† Ù†Ø³Ø®Ù‡ Gemma
]

# Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ… Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class AsyncRateLimiter:
    def __init__(self, rate_limit: int, period: int):
        self.rate_limit = rate_limit
        self.period = period
        self.request_timestamps = []
        self._lock = asyncio.Lock()

    async def __aenter__(self):
        async with self._lock:
            while True:
                now = time.time()
                self.request_timestamps = [
                    t for t in self.request_timestamps if now - t < self.period
                ]
                if len(self.request_timestamps) < self.rate_limit:
                    self.request_timestamps.append(now)
                    break
                
                oldest_request_time = self.request_timestamps[0]
                sleep_duration = self.period - (now - oldest_request_time)
                if sleep_duration > 0:
                    await asyncio.sleep(sleep_duration)

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        pass

# =================================================================================
# --- Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯ ---
# =================================================================================

class SmartCacheManager:
    def __init__(self, cache_file: str, cache_duration_hours: int):
        self.cache_file = cache_file
        self.cache_duration_hours = cache_duration_hours
        self.cache = self.load_cache()
        
    def load_cache(self) -> Dict:
        if not os.path.exists(self.cache_file):
            return {}
        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache = json.load(f)
                return self.clean_old_cache(cache)
        except (json.JSONDecodeError, IOError) as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø´: {e}")
            return {}
    
    def clean_old_cache(self, cache: Dict) -> Dict:
        cleaned_cache = {}
        current_time = datetime.now(UTC)
        
        for pair, cache_data in cache.items():
            if isinstance(cache_data, str):
                last_signal_time = datetime.fromisoformat(cache_data)
                if current_time - last_signal_time < timedelta(hours=self.cache_duration_hours):
                    cleaned_cache[pair] = cache_data
            elif isinstance(cache_data, dict):
                signal_time = datetime.fromisoformat(cache_data.get('timestamp', ''))
                if current_time - signal_time < timedelta(hours=self.cache_duration_hours):
                    cleaned_cache[pair] = cache_data
                    
        return cleaned_cache
    
    def is_pair_on_cooldown(self, pair: str) -> bool:
        if pair not in self.cache:
            return False
            
        cache_data = self.cache[pair]
        if isinstance(cache_data, str):
            last_signal_time = datetime.fromisoformat(cache_data)
        else:
            last_signal_time = datetime.fromisoformat(cache_data.get('timestamp', ''))
            
        if datetime.now(UTC) - last_signal_time < timedelta(hours=self.cache_duration_hours):
            logging.info(f"Ø¬ÙØª Ø§Ø±Ø² {pair} Ø¯Ø± Ø¯ÙˆØ±Ù‡ Ø§Ø³ØªØ±Ø§Ø­Øª Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯")
            return True
        return False
    
    def update_cache(self, pair: str, signal_data: Dict = None):
        self.cache[pair] = {
            'timestamp': datetime.now(UTC).isoformat(),
            'signal': signal_data or {}
        }
        self.save_cache()
    
    def save_cache(self):
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, indent=4, ensure_ascii=False)
        except IOError as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ú©Ø´: {e}")

# =================================================================================
# --- Ú©Ù„Ø§Ø³ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ---
# =================================================================================

class AdvancedTechnicalAnalyzer:
    def __init__(self):
        self.indicators_config = {
            'trend': ['ema_21', 'ema_50', 'ema_200', 'adx_14'],
            'momentum': ['rsi_14', 'stoch_14_3_3', 'macd'],
            'volatility': ['bb_20_2', 'atr_14'],
            'volume': ['obv', 'volume_sma_20'],
            'ichimoku': True,
            'support_resistance': True,
            'candle_patterns': True
        }

    def calculate_advanced_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        if df is None or df.empty or len(df) < 100:
            return None
            
        try:
            # Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ø±ÙˆÙ†Ø¯
            df.ta.ema(length=21, append=True)
            df.ta.ema(length=50, append=True)
            df.ta.ema(length=200, append=True)
            df.ta.adx(length=14, append=True)
            
            # Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù…ÙˆÙ…Ù†ØªÙˆÙ…
            df.ta.rsi(length=14, append=True)
            df.ta.stoch(append=True)
            df.ta.macd(append=True)
            
            # Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù†ÙˆØ³Ø§Ù†
            df.ta.bbands(length=20, std=2, append=True)
            df.ta.atr(length=14, append=True)
            
            # Ø­Ø¬Ù…
            if 'volume' in df.columns and not df['volume'].isnull().all():
                logging.info(f"Ø³ØªÙˆÙ† 'volume' Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ø­Ø¬Ù…...")
                df.ta.obv(append=True)
                df['volume_sma_20'] = df['volume'].rolling(20).mean()
            else:
                logging.warning("Ø³ØªÙˆÙ† 'volume' Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ OBV Ùˆ Volume SMA Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù†Ø¯.")
            
            # Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ
            df.ta.ichimoku(append=True)
            
            # Ø³Ø·ÙˆØ­ Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª
            df['sup_1'] = df['low'].rolling(20).min().shift(1)
            df['res_1'] = df['high'].rolling(20).max().shift(1)
            df['sup_2'] = df['low'].rolling(50).min().shift(1)
            df['res_2'] = df['high'].rolling(50).max().shift(1)
            
            # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©
            if self.indicators_config['candle_patterns']:
                popular_patterns = ['doji', 'hammer', 'engulfing', 'harami', 'morningstar', 'eveningstar']
                for pattern in popular_patterns:
                    try:
                        df.ta.cdl_pattern(name=pattern, append=True)
                    except Exception as e:
                        logging.warning(f"Could not calculate candle pattern '{pattern}': {e}")
                        continue
            
            df.dropna(inplace=True)
            return df
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§: {e}")
            return None

    def generate_technical_analysis(self, symbol: str, htf_df: pd.DataFrame, ltf_df: pd.DataFrame) -> Dict:
        if htf_df.empty or ltf_df.empty:
            return None
            
        last_htf = htf_df.iloc[-1]
        last_ltf = ltf_df.iloc[-1]
        prev_ltf = ltf_df.iloc[-2] if len(ltf_df) > 1 else last_ltf
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯
        htf_trend = self._analyze_trend(last_htf)
        ltf_trend = self._analyze_trend(last_ltf)
        
        # ØªØ­Ù„ÛŒÙ„ Ù…ÙˆÙ…Ù†ØªÙˆÙ…
        momentum = self._analyze_momentum(last_ltf)
        
        # ØªØ­Ù„ÛŒÙ„ Ø³Ø·ÙˆØ­ Ú©Ù„ÛŒØ¯ÛŒ
        key_levels = self._analyze_key_levels(htf_df, ltf_df, last_ltf['close'])
        
        # ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©
        candle_analysis = self._analyze_candle_patterns(ltf_df)
        
        # ØªØ­Ù„ÛŒÙ„ Ø­Ø¬Ù… (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
        volume_analysis = self._analyze_volume(ltf_df)
        
        return {
            'symbol': symbol,
            'htf_trend': htf_trend,
            'ltf_trend': ltf_trend,
            'momentum': momentum,
            'key_levels': key_levels,
            'candle_patterns': candle_analysis,
            'volume_analysis': volume_analysis,
            'volatility': last_ltf.get('ATRr_14', 0),
            'timestamp': datetime.now(UTC).isoformat()
        }

    def _analyze_trend(self, data: pd.Series) -> Dict:
        ema_21 = data.get('EMA_21', 0)
        ema_50 = data.get('EMA_50', 0)
        ema_200 = data.get('EMA_200', 0)
        adx = data.get('ADX_14', 0)
        
        # ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ØªØ± Ø±ÙˆÙ†Ø¯
        trend_strength = "Ø¨Ø³ÛŒØ§Ø± Ù‚ÙˆÛŒ" if adx > 40 else "Ù‚ÙˆÛŒ" if adx > 25 else "Ù…ØªÙˆØ³Ø·" if adx > 20 else "Ø¶Ø¹ÛŒÙ"
        
        if ema_21 > ema_50 > ema_200:
            trend_direction = "ØµØ¹ÙˆØ¯ÛŒ Ù‚ÙˆÛŒ"
        elif ema_21 < ema_50 < ema_200:
            trend_direction = "Ù†Ø²ÙˆÙ„ÛŒ Ù‚ÙˆÛŒ"
        elif ema_21 > ema_50 and ema_50 > ema_200:
            trend_direction = "ØµØ¹ÙˆØ¯ÛŒ"
        elif ema_21 < ema_50 and ema_50 < ema_200:
            trend_direction = "Ù†Ø²ÙˆÙ„ÛŒ"
        else:
            trend_direction = "Ø®Ù†Ø«ÛŒ"
        
        return {
            'direction': trend_direction,
            'strength': trend_strength,
            'adx': adx,
            'ema_alignment': f"EMA21: {ema_21:.5f}, EMA50: {ema_50:.5f}, EMA200: {ema_200:.5f}"
        }

    def _analyze_momentum(self, data: pd.Series) -> Dict:
        rsi = data.get('RSI_14', 50)
        macd_hist = data.get('MACDh_12_26_9', 0)
        stoch_k = data.get('STOCHk_14_3_3', 50)
        stoch_d = data.get('STOCHd_14_3_3', 50)
        
        # ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ RSI
        if rsi > 80:
            rsi_signal = "Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯ Ø´Ø¯ÛŒØ¯"
        elif rsi > 70:
            rsi_signal = "Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯"
        elif rsi < 20:
            rsi_signal = "Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´ Ø´Ø¯ÛŒØ¯"
        elif rsi < 30:
            rsi_signal = "Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´"
        else:
            rsi_signal = "Ø®Ù†Ø«ÛŒ"
        
        # ØªØ­Ù„ÛŒÙ„ MACD
        macd_signal = "ØµØ¹ÙˆØ¯ÛŒ Ù‚ÙˆÛŒ" if macd_hist > 0.001 else "ØµØ¹ÙˆØ¯ÛŒ" if macd_hist > 0 else "Ù†Ø²ÙˆÙ„ÛŒ" if macd_hist < -0.001 else "Ù†Ø²ÙˆÙ„ÛŒ Ù‚ÙˆÛŒ"
        
        # ØªØ­Ù„ÛŒÙ„ Stochastic
        stoch_signal = "Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯" if stoch_k > 80 else "Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´" if stoch_k < 20 else "Ø®Ù†Ø«ÛŒ"
        stoch_cross = "Ø·Ù„Ø§ÛŒÛŒ" if stoch_k > stoch_d and data.get('STOCHk_14_3_3_1', 50) <= data.get('STOCHd_14_3_3_1', 50) else "Ù…Ø±Ø¯Ù‡" if stoch_k < stoch_d and data.get('STOCHk_14_3_3_1', 50) >= data.get('STOCHd_14_3_3_1', 50) else "Ø¨Ø¯ÙˆÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„"
        
        return {
            'rsi': {'value': rsi, 'signal': rsi_signal},
            'macd': {'signal': macd_signal, 'histogram': macd_hist},
            'stochastic': {
                'value': stoch_k, 
                'signal': stoch_signal,
                'cross': stoch_cross
            }
        }

    def _analyze_key_levels(self, htf_df: pd.DataFrame, ltf_df: pd.DataFrame, current_price: float) -> Dict:
        # Ø³Ø·ÙˆØ­ Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ©
        bb_upper = ltf_df.get('BBU_20_2.0', pd.Series([0])).iloc[-1]
        bb_lower = ltf_df.get('BBL_20_2.0', pd.Series([0])).iloc[-1]
        bb_middle = ltf_df.get('BBM_20_2.0', pd.Series([0])).iloc[-1]
        
        # Ø³Ø·ÙˆØ­ Ø§Ø³ØªØ§ØªÛŒÚ©
        support_1 = ltf_df.get('sup_1', pd.Series([0])).iloc[-1]
        resistance_1 = ltf_df.get('res_1', pd.Series([0])).iloc[-1]
        support_2 = ltf_df.get('sup_2', pd.Series([0])).iloc[-1]
        resistance_2 = ltf_df.get('res_2', pd.Series([0])).iloc[-1]
        
        # Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ (Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø§Ø¯Ù‡)
        recent_high = ltf_df['high'].max()
        recent_low = ltf_df['low'].min()
        fib_levels = self._calculate_fibonacci_levels(recent_high, recent_low)
        
        return {
            'dynamic': {
                'bb_upper': bb_upper,
                'bb_lower': bb_lower,
                'bb_middle': bb_middle
            },
            'static': {
                'support_1': support_1,
                'resistance_1': resistance_1,
                'support_2': support_2,
                'resistance_2': resistance_2
            },
            'fibonacci': fib_levels,
            'current_price_position': self._get_price_position(current_price, support_1, resistance_1),
            'bb_position': self._get_bb_position(current_price, bb_upper, bb_lower)
        }

    def _calculate_fibonacci_levels(self, high: float, low: float) -> Dict:
        diff = high - low
        return {
            '0.0': high,
            '0.236': high - 0.236 * diff,
            '0.382': high - 0.382 * diff,
            '0.5': high - 0.5 * diff,
            '0.618': high - 0.618 * diff,
            '0.786': high - 0.786 * diff,
            '1.0': low
        }

    def _get_price_position(self, price: float, support: float, resistance: float) -> str:
        if resistance == support or resistance <= support:
            return "Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø®Ù†Ø«ÛŒ"
        
        range_size = resistance - support
        position = (price - support) / range_size
        
        if position < 0.2:
            return "Ù†Ø²Ø¯ÛŒÚ© Ø­Ù…Ø§ÛŒØª Ù‚ÙˆÛŒ"
        elif position < 0.4:
            return "Ù†Ø²Ø¯ÛŒÚ© Ø­Ù…Ø§ÛŒØª"
        elif position > 0.8:
            return "Ù†Ø²Ø¯ÛŒÚ© Ù…Ù‚Ø§ÙˆÙ…Øª Ù‚ÙˆÛŒ"
        elif position > 0.6:
            return "Ù†Ø²Ø¯ÛŒÚ© Ù…Ù‚Ø§ÙˆÙ…Øª"
        else:
            return "Ø¯Ø± Ù…ÛŒØ§Ù†Ù‡ Ø±Ù†Ø¬"

    def _get_bb_position(self, price: float, bb_upper: float, bb_lower: float) -> str:
        if price >= bb_upper:
            return "Ø¨Ø§Ù„Ø§ÛŒ Ø¨Ø§Ù†Ø¯ Ø¨Ø§Ù„Ø§ÛŒÛŒ"
        elif price <= bb_lower:
            return "Ø²ÛŒØ± Ø¨Ø§Ù†Ø¯ Ù¾Ø§ÛŒÛŒÙ†ÛŒ"
        elif abs(price - bb_upper) < abs(price - bb_lower):
            return "Ù†Ø²Ø¯ÛŒÚ© Ø¨Ø§Ù†Ø¯ Ø¨Ø§Ù„Ø§ÛŒÛŒ"
        else:
            return "Ù†Ø²Ø¯ÛŒÚ© Ø¨Ø§Ù†Ø¯ Ù¾Ø§ÛŒÛŒÙ†ÛŒ"

    def _analyze_volume(self, df: pd.DataFrame) -> Dict:
        if 'volume' not in df.columns or df['volume'].isnull().all():
            return {'signal': 'Ø¯Ø§Ø¯Ù‡ Ø­Ø¬Ù… Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª', 'trend': 'Ù†Ø§Ù…Ø´Ø®Øµ'}
        
        current_volume = df['volume'].iloc[-1]
        avg_volume = df['volume'].tail(20).mean()
        
        volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1
        
        if volume_ratio > 2:
            volume_signal = "Ø­Ø¬Ù… Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§"
        elif volume_ratio > 1.5:
            volume_signal = "Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§"
        elif volume_ratio < 0.5:
            volume_signal = "Ø­Ø¬Ù… Ø¨Ø³ÛŒØ§Ø± Ù¾Ø§ÛŒÛŒÙ†"
        elif volume_ratio < 0.8:
            volume_signal = "Ø­Ø¬Ù… Ù¾Ø§ÛŒÛŒÙ†"
        else:
            volume_signal = "Ø­Ø¬Ù… Ù†Ø±Ù…Ø§Ù„"
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ Ø­Ø¬Ù…
        volume_trend = "ØµØ¹ÙˆØ¯ÛŒ" if current_volume > df['volume'].iloc[-2] else "Ù†Ø²ÙˆÙ„ÛŒ"
        
        return {
            'signal': volume_signal,
            'trend': volume_trend,
            'ratio': round(volume_ratio, 2)
        }

    def _analyze_candle_patterns(self, df: pd.DataFrame) -> Dict:
        if len(df) < 3:
            return {'patterns': [], 'current_candle': {}, 'recent_patterns': []}
            
        last_candle = df.iloc[-1]
        patterns = []
        
        candle_indicators = [col for col in df.columns if col.startswith('CDL_')]
        for indicator in candle_indicators:
            if abs(last_candle.get(indicator, 0)) > 0:
                pattern_name = indicator.replace('CDL_', '')
                direction = "ØµØ¹ÙˆØ¯ÛŒ" if last_candle[indicator] > 0 else "Ù†Ø²ÙˆÙ„ÛŒ"
                strength = "Ù‚ÙˆÛŒ" if abs(last_candle[indicator]) > 50 else "Ù…ØªÙˆØ³Ø·"
                patterns.append(f"{pattern_name} ({direction} - {strength})")
        
        current_candle = self._analyze_single_candle(df.iloc[-1])
        
        # ØªØ­Ù„ÛŒÙ„ 3 Ú©Ù†Ø¯Ù„ Ø§Ø®ÛŒØ±
        recent_candles = []
        for i in range(1, 4):
            if len(df) >= i:
                recent_candles.append(self._analyze_single_candle(df.iloc[-i]))
        
        return {
            'patterns': patterns,
            'current_candle': current_candle,
            'recent_candles': recent_candles,
            'recent_patterns': patterns[-3:] if patterns else []
        }

    def _analyze_single_candle(self, candle: pd.Series) -> Dict:
        open_price = candle.get('open', 0)
        close = candle.get('close', 0)
        high = candle.get('high', 0)
        low = candle.get('low', 0)
        
        body_size = abs(close - open_price)
        total_range = high - low
        upper_shadow = high - max(open_price, close)
        lower_shadow = min(open_price, close) - low
        
        if total_range == 0:
            return {"type": "ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡", "direction": "Ø®Ù†Ø«ÛŒ", "body_ratio": 0, "strength": "Ø¶Ø¹ÛŒÙ"}
            
        body_ratio = body_size / total_range
        upper_shadow_ratio = upper_shadow / total_range
        lower_shadow_ratio = lower_shadow / total_range
        
        # ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù†ÙˆØ¹ Ú©Ù†Ø¯Ù„
        if body_ratio < 0.1:
            candle_type = "Ø¯ÙˆØ¬ÛŒ"
        elif body_ratio < 0.3:
            if upper_shadow_ratio > 0.6:
                candle_type = "Ú†Ú©Ø´ ÙˆØ§Ø±ÙˆÙ†Ù‡"
            elif lower_shadow_ratio > 0.6:
                candle_type = "Ú†Ú©Ø´"
            else:
                candle_type = "ÙØ±ÙØ±Ù‡"
        elif body_ratio > 0.7:
            candle_type = "Ù…Ø§Ø±ÙˆØ¨ÙˆØ²Ùˆ"
        else:
            candle_type = "Ø¹Ø§Ø¯ÛŒ"
            
        direction = "ØµØ¹ÙˆØ¯ÛŒ" if close > open_price else "Ù†Ø²ÙˆÙ„ÛŒ"
        strength = "Ø¨Ø³ÛŒØ§Ø± Ù‚ÙˆÛŒ" if body_ratio > 0.8 else "Ù‚ÙˆÛŒ" if body_ratio > 0.6 else "Ù…ØªÙˆØ³Ø·" if body_ratio > 0.3 else "Ø¶Ø¹ÛŒÙ"
        
        return {
            'type': candle_type,
            'direction': direction,
            'body_ratio': round(body_ratio, 2),
            'strength': strength,
            'upper_shadow_ratio': round(upper_shadow_ratio, 2),
            'lower_shadow_ratio': round(lower_shadow_ratio, 2)
        }

# =================================================================================
# --- Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª AI Ú†Ù‡Ø§Ø±Ú¯Ø§Ù†Ù‡ (Gemini + 2 Ù…Ø¯Ù„ Cloudflare + Groq) ---
# =================================================================================

class QuadAIManager:
    def __init__(self, gemini_api_key: str, cloudflare_api_key: str, groq_api_key: str):
        self.gemini_api_key = gemini_api_key
        self.cloudflare_api_key = cloudflare_api_key
        self.groq_api_key = groq_api_key
        self.gemini_model = GEMINI_MODEL
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Cloudflare
        self.cloudflare_account_id = os.getenv("CLOUDFLARE_ACCOUNT_ID", "your_account_id")
        self.cloudflare_models = CLOUDFLARE_MODELS
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Groq
        self.groq_client = Groq(api_key=groq_api_key) if groq_api_key else None
        self.groq_models = GROQ_MODELS
        
        genai.configure(api_key=gemini_api_key)
    
    async def get_quad_analysis(self, symbol: str, technical_analysis: Dict) -> Optional[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ Ø§Ø² Ú†Ù‡Ø§Ø± Ù…Ø¯Ù„ AI Ùˆ Ø¨Ø±Ø±Ø³ÛŒ ØªÙˆØ§ÙÙ‚"""
        tasks = [
            self._get_gemini_analysis(symbol, technical_analysis),
            self._get_cloudflare_analysis(symbol, technical_analysis, self.cloudflare_models[0], "Llama"),
            self._get_cloudflare_analysis(symbol, technical_analysis, self.cloudflare_models[1], "DeepSeek"),
            self._get_groq_analysis(symbol, technical_analysis, self.groq_models[0], "Groq-Llama"),
            self._get_groq_analysis(symbol, technical_analysis, self.groq_models[1], "Groq-Mixtral")
        ]
        
        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Ù„Ø§Ú¯ Ø®Ø·Ø§Ù‡Ø§
            model_names = ["Gemini", "Llama", "DeepSeek", "Groq-Llama", "Groq-Mixtral"]
            valid_results = []
            
            for i, (name, result) in enumerate(zip(model_names, results)):
                if isinstance(result, Exception):
                    logging.error(f"Ø®Ø·Ø§ Ø¯Ø± {name} Ø¨Ø±Ø§ÛŒ {symbol}: {result}")
                elif result is not None:
                    valid_results.append((name, result))
            
            return self._combine_and_classify_signals(symbol, valid_results, technical_analysis)
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ú†Ù‡Ø§Ø±Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return None
    
    async def _get_gemini_analysis(self, symbol: str, technical_analysis: Dict) -> Optional[Dict]:
        """ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Gemini"""
        try:
            prompt = self._create_advanced_analysis_prompt(symbol, technical_analysis)
            model = genai.GenerativeModel(self.gemini_model)
            
            response = await asyncio.to_thread(
                model.generate_content,
                prompt,
                request_options={'timeout': 120}
            )
            
            return self._parse_ai_response(response.text, symbol, "Gemini")
            
        except Exception as e:
            logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Gemini Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return None
    
    async def _get_cloudflare_analysis(self, symbol: str, technical_analysis: Dict, model_name: str, model_display_name: str) -> Optional[Dict]:
        """ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Cloudflare AI"""
        if not self.cloudflare_api_key or self.cloudflare_account_id == "your_account_id":
            logging.warning("Ú©Ù„ÛŒØ¯ ÛŒØ§ Ø´Ù†Ø§Ø³Ù‡ Ø­Ø³Ø§Ø¨ Cloudflare API ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
            return None
            
        try:
            prompt = self._create_advanced_analysis_prompt(symbol, technical_analysis)
            
            headers = {
                "Authorization": f"Bearer {self.cloudflare_api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "messages": [
                    {
                        "role": "system", 
                        "content": "Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§Ø²Ø§Ø± ÙØ§Ø±Ú©Ø³ Ù‡Ø³ØªÛŒØ¯. Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ¯ Ø±Ø§ ÙÙ‚Ø· Ø¯Ø± Ù‚Ø§Ù„Ø¨ JSON Ù…Ø¹ØªØ¨Ø± Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯."
                    },
                    {"role": "user", "content": prompt}
                ],
                "stream": False
            }
            
            url = f"https://api.cloudflare.com/client/v4/accounts/{self.cloudflare_account_id}/ai/run/{model_name}"
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, headers=headers, json=payload, timeout=120) as response:
                    if response.status == 200:
                        data = await response.json()
                        if "result" in data and "response" in data["result"]:
                            content = data["result"]["response"]
                            return self._parse_ai_response(content, symbol, model_display_name)
                        elif "response" in data:
                            content = data["response"]
                            return self._parse_ai_response(content, symbol, model_display_name)
                        else:
                            logging.warning(f"ÙØ±Ù…Øª Ù¾Ø§Ø³Ø® Cloudflare Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª: {data}")
                            return None
                    else:
                        error_text = await response.text()
                        logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø³Ø® Cloudflare: {response.status} - {error_text}")
                        return None
                        
        except Exception as e:
            logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ {model_display_name} Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return None

    async def _get_groq_analysis(self, symbol: str, technical_analysis: Dict, model_name: str, model_display_name: str) -> Optional[Dict]:
        """ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Groq API"""
        if not self.groq_client:
            logging.warning("Ú©Ù„ÛŒØ¯ Groq API ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
            return None
            
        try:
            prompt = self._create_advanced_analysis_prompt(symbol, technical_analysis)
            
            response = await asyncio.to_thread(
                self.groq_client.chat.completions.create,
                messages=[
                    {
                        "role": "system",
                        "content": "Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§Ø²Ø§Ø± ÙØ§Ø±Ú©Ø³ Ù‡Ø³ØªÛŒØ¯. Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ¯ Ø±Ø§ ÙÙ‚Ø· Ø¯Ø± Ù‚Ø§Ù„Ø¨ JSON Ù…Ø¹ØªØ¨Ø± Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                model=model_name,
                temperature=0.1,
                max_tokens=1024,
                timeout=120
            )
            
            content = response.choices[0].message.content
            return self._parse_ai_response(content, symbol, model_display_name)
            
        except Exception as e:
            logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ {model_display_name} Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return None

    def _create_advanced_analysis_prompt(self, symbol: str, technical_analysis: Dict) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø±Ø§Ù…Ù¾Øª ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø³ÛŒÚ¯Ù†Ø§Ù„"""
        ta = technical_analysis
        
        return f"""
Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø®Ø¨Ø±Ù‡ Ø¨Ø§Ø²Ø§Ø± ÙØ§Ø±Ú©Ø³ØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø²ÛŒØ± Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯ Ùˆ Ø¨Ù‡ØªØ±ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ù…Ø§ÛŒÛŒØ¯.

ğŸ¯ **Ø¬ÙØª Ø§Ø±Ø²: {symbol}**

ğŸ“Š **ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯:**
- Ø±ÙˆÙ†Ø¯ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª (4H): {ta['htf_trend']['direction']} - Ù‚Ø¯Ø±Øª: {ta['htf_trend']['strength']} (ADX: {ta['htf_trend']['adx']:.1f})
- Ø±ÙˆÙ†Ø¯ Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª (1H): {ta['ltf_trend']['direction']}
- Ù‡Ù…Ø³ÙˆÛŒÛŒ Ø±ÙˆÙ†Ø¯Ù‡Ø§: {'Ù‡Ù…Ø³Ùˆ' if ta['htf_trend']['direction'] == ta['ltf_trend']['direction'] else 'ØºÛŒØ± Ù‡Ù…Ø³Ùˆ'}

ğŸ’ª **ØªØ­Ù„ÛŒÙ„ Ù…ÙˆÙ…Ù†ØªÙˆÙ…:**
- RSI: {ta['momentum']['rsi']['value']:.1f} - Ø³ÛŒÚ¯Ù†Ø§Ù„: {ta['momentum']['rsi']['signal']}
- MACD: {ta['momentum']['macd']['signal']} (Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù…: {ta['momentum']['macd']['histogram']:.5f})
- Stochastic: {ta['momentum']['stochastic']['value']:.1f} - Ø³ÛŒÚ¯Ù†Ø§Ù„: {ta['momentum']['stochastic']['signal']} - Ú©Ø±Ø§Ø³: {ta['momentum']['stochastic']['cross']}

ğŸ¯ **Ø³Ø·ÙˆØ­ Ú©Ù„ÛŒØ¯ÛŒ:**
- Ù…ÙˆÙ‚Ø¹ÛŒØª Ù‚ÛŒÙ…Øª: {ta['key_levels']['current_price_position']}
- Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¯Ø± Ø¨Ø§Ù†Ø¯ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±: {ta['key_levels']['bb_position']}
- Ù…Ù‚Ø§ÙˆÙ…Øª ÙÙˆØ±ÛŒ: {ta['key_levels']['static']['resistance_1']:.5f}
- Ø­Ù…Ø§ÛŒØª ÙÙˆØ±ÛŒ: {ta['key_levels']['static']['support_1']:.5f}

ğŸ•¯ï¸ **Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©:**
- Ú©Ù†Ø¯Ù„ ÙØ¹Ù„ÛŒ: {ta['candle_patterns']['current_candle']['type']} - {ta['candle_patterns']['current_candle']['direction']} - Ù‚Ø¯Ø±Øª: {ta['candle_patterns']['current_candle']['strength']}
- Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡: {', '.join(ta['candle_patterns']['patterns']) if ta['candle_patterns']['patterns'] else 'Ù‡ÛŒÚ† Ø§Ù„Ú¯ÙˆÛŒ Ù…Ø´Ø®ØµÛŒ'}

ğŸ“ˆ **ØªØ­Ù„ÛŒÙ„ Ø­Ø¬Ù…:**
- Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø­Ø¬Ù…: {ta['volume_analysis']['signal']}
- Ø±ÙˆÙ†Ø¯ Ø­Ø¬Ù…: {ta['volume_analysis']['trend']} (Ù†Ø³Ø¨Øª: {ta['volume_analysis']['ratio']})

âš ï¸ **Ø±ÛŒØ³Ú© Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª:**
- Ù†ÙˆØ³Ø§Ù† (ATR): {ta['volatility']:.5f}
- ÙØ§ØµÙ„Ù‡ ØªØ§ Ø³Ø·ÙˆØ­ Ú©Ù„ÛŒØ¯ÛŒ: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ù†ÛŒØ¯

**Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ù„Ø§ØŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø±Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ JSON Ø²ÛŒØ± Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯:**

{{
  "SYMBOL": "{symbol}",
  "ACTION": "BUY/SELL/HOLD",
  "CONFIDENCE": 1-10,
  "ENTRY_ZONE": "Ù…Ø­Ø¯ÙˆØ¯Ù‡ ÙˆØ±ÙˆØ¯ (Ù…Ø«Ø§Ù„: 1.12340-1.12400)",
  "STOP_LOSS": "Ø¹Ø¯Ø¯ Ø§Ø¹Ø´Ø§Ø±ÛŒ Ø¯Ù‚ÛŒÙ‚", 
  "TAKE_PROFIT_1": "Ø¹Ø¯Ø¯ Ø§Ø¹Ø´Ø§Ø±ÛŒ Ø¯Ù‚ÛŒÙ‚",
  "TAKE_PROFIT_2": "Ø¹Ø¯Ø¯ Ø§Ø¹Ø´Ø§Ø±ÛŒ Ø¯Ù‚ÛŒÙ‚",
  "RISK_REWARD_RATIO": "Ù†Ø³Ø¨Øª Ø¹Ø¯Ø¯ÛŒ",
  "ANALYSIS": "ØªØ­Ù„ÛŒÙ„ ØªÙØµÛŒÙ„ÛŒ ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Ø°Ú©Ø± Ø¯Ù„Ø§ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„",
  "EXPIRATION_H": 4-8,
  "PRIORITY": "HIGH/MEDIUM/LOW"
}}

**Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…:**
- Ø§Ú¯Ø± RSI Ø¯Ø± Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯/ÙØ±ÙˆØ´ Ø´Ø¯ÛŒØ¯ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø­ØªÛŒØ§Ø· Ú©Ù†ÛŒØ¯
- Ù‡Ù…Ø³ÙˆÛŒÛŒ Ø±ÙˆÙ†Ø¯Ù‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª Ø§Ù…ØªÛŒØ§Ø² Ù…Ø«Ø¨Øª Ø¯Ø§Ø±Ø¯
- Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ Ø¯Ø± Ø¬Ù‡Øª Ø±ÙˆÙ†Ø¯ ØªØ£ÛŒÛŒØ¯ Ú©Ù†Ù†Ø¯Ù‡ Ø§Ø³Øª
- Ù…ÙˆÙ‚Ø¹ÛŒØª Ù‚ÛŒÙ…Øª Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø³Ø·ÙˆØ­ ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±ÛŒØ¯
"""

    def _parse_ai_response(self, response: str, symbol: str, ai_name: str) -> Optional[Dict]:
        """Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø® AI"""
        try:
            cleaned_response = response.strip()
            
            json_patterns = [
                r'```json\s*(\{.*?\})\s*```',
                r'```\s*(\{.*?\})\s*```',
                r'(\{.*\})'
            ]
            
            json_match = None
            for pattern in json_patterns:
                json_match = re.search(pattern, cleaned_response, re.DOTALL)
                if json_match:
                    break
            
            if json_match:
                json_str = json_match.group(1)
                signal_data = json.loads(json_str)
                
                if not self._validate_signal_data(signal_data, symbol):
                    return None
                
                signal_data['ai_model'] = ai_name
                signal_data['timestamp'] = datetime.now(UTC).isoformat()
                logging.info(f"âœ… {ai_name} Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ {symbol}: {signal_data.get('ACTION', 'HOLD')} (Ø§Ø¹ØªÙ…Ø§Ø¯: {signal_data.get('CONFIDENCE', 0)})")
                return signal_data
            else:
                logging.warning(f"âŒ Ù¾Ø§Ø³Ø® {ai_name} Ø¨Ø±Ø§ÛŒ {symbol} ÙØ§Ù‚Ø¯ ÙØ±Ù…Øª JSON Ø¨ÙˆØ¯")
                return None
                
        except json.JSONDecodeError as e:
            logging.error(f"Ø®Ø·Ø§ÛŒ JSON Ø¯Ø± Ù¾Ø§Ø³Ø® {ai_name} Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return None
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø® {ai_name} Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return None

    def _validate_signal_data(self, signal_data: Dict, symbol: str) -> bool:
        """Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„"""
        required_fields = ['SYMBOL', 'ACTION', 'CONFIDENCE']
        
        for field in required_fields:
            if field not in signal_data:
                logging.warning(f"ÙÛŒÙ„Ø¯ Ø¶Ø±ÙˆØ±ÛŒ {field} Ø¯Ø± Ø³ÛŒÚ¯Ù†Ø§Ù„ {symbol} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
                return False
        
        action = signal_data['ACTION'].upper()
        if action not in ['BUY', 'SELL', 'HOLD']:
            logging.warning(f"ACTION Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ {symbol}: {action}")
            return False
        
        try:
            confidence = float(signal_data['CONFIDENCE'])
            if not (1 <= confidence <= 10):
                logging.warning(f"CONFIDENCE Ø®Ø§Ø±Ø¬ Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol}: {confidence}")
                return False
        except (ValueError, TypeError):
            logging.warning(f"CONFIDENCE Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ {symbol}: {signal_data['CONFIDENCE']}")
            return False
        
        return True

    def _extract_numeric_value(self, value: str) -> Optional[float]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§ÛŒÙ…Ù† Ù…Ù‚Ø¯Ø§Ø± Ø¹Ø¯Ø¯ÛŒ Ø§Ø² Ø±Ø´ØªÙ‡"""
        if isinstance(value, (int, float)):
            return float(value)
        if not isinstance(value, str):
            return None
            
        match = re.search(r'[-+]?\d*\.\d+|\d+', value.replace(',', ''))
        if match:
            try:
                return float(match.group(0))
            except (ValueError, TypeError):
                return None
        return None

    def _combine_and_classify_signals(self, symbol: str, valid_results: List[Tuple[str, Dict]], technical_analysis: Dict) -> Optional[Dict]:
        """ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI Ùˆ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªÙˆØ§ÙÙ‚"""
        if not valid_results:
            logging.info(f"Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return {
                'SYMBOL': symbol, 
                'ACTION': 'HOLD', 
                'CONFIDENCE': 0,
                'AGREEMENT_LEVEL': 0,
                'AGREEMENT_TYPE': 'NO_CONSENSUS',
                'VALID_MODELS': 0,
                'ANALYSIS': 'Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹ØªØ¨Ø± Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI'
            }
        
        # Ø´Ù…Ø§Ø±Ø´ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        action_counts = {}
        for model_name, result in valid_results:
            action = result['ACTION'].upper()
            action_counts[action] = action_counts.get(action, 0) + 1
        
        # ØªØ¹ÛŒÛŒÙ† Ø³Ø·Ø­ ØªÙˆØ§ÙÙ‚
        total_models = len(valid_results)
        max_agreement = max(action_counts.values())
        agreement_level = max_agreement
        
        if agreement_level >= 3:
            # Ø§Ú©Ø«Ø±ÛŒØª Ù‚ÙˆÛŒ (3 ÛŒØ§ 4 Ù…Ø¯Ù„ Ù…ÙˆØ§ÙÙ‚)
            majority_action = max(action_counts, key=action_counts.get)
            agreement_type = 'STRONG_CONSENSUS'
            agreeing_results = [result for _, result in valid_results if result['ACTION'].upper() == majority_action]
            combined_signal = self._average_agreeing_signals(symbol, agreeing_results, majority_action)
            
        elif agreement_level == 2:
            # Ø§Ú©Ø«Ø±ÛŒØª Ø¶Ø¹ÛŒÙ (2 Ù…Ø¯Ù„ Ù…ÙˆØ§ÙÙ‚)
            majority_action = max(action_counts, key=action_counts.get)
            agreement_type = 'WEAK_CONSENSUS'
            agreeing_results = [result for _, result in valid_results if result['ACTION'].upper() == majority_action]
            combined_signal = self._average_agreeing_signals(symbol, agreeing_results, majority_action)
            # Ú©Ø§Ù‡Ø´ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨Ø±Ø§ÛŒ ØªÙˆØ§ÙÙ‚ Ø¶Ø¹ÛŒÙ
            combined_signal['CONFIDENCE'] = max(1, int(float(combined_signal.get('CONFIDENCE', 5)) - 1))
            
        else:
            # Ø¹Ø¯Ù… ØªÙˆØ§ÙÙ‚
            agreement_type = 'NO_CONSENSUS'
            # Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø§Ø¹ØªÙ…Ø§Ø¯
            highest_confidence_model = max(valid_results, key=lambda x: float(x[1].get('CONFIDENCE', 0)))
            combined_signal = highest_confidence_model[1]
            combined_signal['CONFIDENCE'] = max(1, int(float(combined_signal.get('CONFIDENCE', 5)) - 2))
        
        combined_signal['AGREEMENT_LEVEL'] = agreement_level
        combined_signal['AGREEMENT_TYPE'] = agreement_type
        combined_signal['VALID_MODELS'] = total_models
        combined_signal['TOTAL_MODELS_ANALYZED'] = 5  # ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø¯Ù„â€ŒÙ‡Ø§
        combined_signal['CONSENSUS_ANALYSIS'] = self._generate_consensus_analysis(agreement_type, agreement_level, total_models)
        
        return combined_signal

    def _average_agreeing_signals(self, symbol: str, agreeing_results: List[Dict], majority_action: str) -> Dict:
        """Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÚ¯ÛŒØ±ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ§ÙÙ‚"""
        if len(agreeing_results) == 1:
            result = agreeing_results[0]
            result['CONSENSUS_DETAIL'] = f"Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø§Ø² {result['ai_model']} - Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ£ÛŒÛŒØ¯ Ø¨ÛŒØ´ØªØ±"
            return result
        
        averaged = {'SYMBOL': symbol, 'ACTION': majority_action}
        
        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† CONFIDENCE
        confidences = [float(result.get('CONFIDENCE', 5)) for result in agreeing_results]
        averaged['CONFIDENCE'] = round(sum(confidences) / len(confidences), 1)
        
        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¹Ø¯Ø¯ÛŒ
        numeric_fields = ['ENTRY_ZONE', 'STOP_LOSS', 'TAKE_PROFIT_1', 'TAKE_PROFIT_2', 'EXPIRATION_H']
        
        for field in numeric_fields:
            values = []
            for result in agreeing_results:
                if field in result:
                    val = self._extract_numeric_value(result[field])
                    if val is not None:
                        values.append(val)
            
            if values:
                avg_val = sum(values) / len(values)
                if field == 'EXPIRATION_H':
                    averaged[field] = int(round(avg_val))
                else:
                    averaged[field] = round(avg_val, 5)
        
        # Ø³Ø§ÛŒØ± ÙÛŒÙ„Ø¯Ù‡Ø§
        averaged['RISK_REWARD_RATIO'] = agreeing_results[0].get('RISK_REWARD_RATIO', 'N/A')
        averaged['PRIORITY'] = self._calculate_priority(agreeing_results)
        
        # Ø°Ø®ÛŒØ±Ù‡ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        model_analyses = {}
        for result in agreeing_results:
            model_analyses[result['ai_model']] = result.get('ANALYSIS', '')
        
        averaged['MODEL_ANALYSES'] = model_analyses
        averaged['CONSENSUS_DETAIL'] = f"ØªÙˆØ§ÙÙ‚ Ø¨ÛŒÙ† {len(agreeing_results)} Ù…Ø¯Ù„ Ø§Ø² {len(agreeing_results)} Ù…Ø¯Ù„ Ù…Ø¹ØªØ¨Ø±"
        
        return averaged

    def _calculate_priority(self, agreeing_results: List[Dict]) -> str:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ø¹ØªÙ…Ø§Ø¯"""
        avg_confidence = sum(float(r.get('CONFIDENCE', 5)) for r in agreeing_results) / len(agreeing_results)
        
        if avg_confidence >= 8:
            return "HIGH"
        elif avg_confidence >= 6:
            return "MEDIUM"
        else:
            return "LOW"

    def _generate_consensus_analysis(self, agreement_type: str, agreement_level: int, total_models: int) -> str:
        """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ ØªÙˆØ§ÙÙ‚"""
        if agreement_type == 'STRONG_CONSENSUS':
            if agreement_level >= 4:
                return "ØªÙˆØ§ÙÙ‚ Ù‚ÙˆÛŒ Ø¨ÛŒÙ† Ø§Ú©Ø«Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI - Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§"
            else:
                return f"ØªÙˆØ§ÙÙ‚ Ù‚ÙˆÛŒ Ø¨ÛŒÙ† {agreement_level} Ù…Ø¯Ù„ Ø§Ø² {total_models} Ù…Ø¯Ù„ - Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨Ø§Ù„Ø§"
        elif agreement_type == 'WEAK_CONSENSUS':
            return f"ØªÙˆØ§ÙÙ‚ Ø¶Ø¹ÛŒÙ Ø¨ÛŒÙ† {agreement_level} Ù…Ø¯Ù„ Ø§Ø² {total_models} Ù…Ø¯Ù„ - Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø­ØªÛŒØ§Ø·"
        else:
            return "Ø¹Ø¯Ù… ØªÙˆØ§ÙÙ‚ Ø¨ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ - Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ Ø§Ø¹ØªÙ…Ø§Ø¯ Ù¾Ø§ÛŒÛŒÙ†"

# =================================================================================
# --- Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ ØªØ­Ù„ÛŒÙ„Ú¯Ø± ÙØ§Ø±Ú©Ø³ ---
# =================================================================================

class AdvancedForexAnalyzer:
    def __init__(self):
        self.api_rate_limiter = AsyncRateLimiter(rate_limit=8, period=60)
        self.cache_manager = SmartCacheManager(CACHE_FILE, CACHE_DURATION_HOURS)
        self.technical_analyzer = AdvancedTechnicalAnalyzer()
        self.ai_manager = QuadAIManager(google_api_key, CLOUDFLARE_AI_API_KEY, GROQ_API_KEY)

    async def analyze_pair(self, pair: str) -> Optional[Dict]:
        """ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ ÛŒÚ© Ø¬ÙØª Ø§Ø±Ø²"""
        if self.cache_manager.is_pair_on_cooldown(pair):
            return None
        
        logging.info(f"ğŸ” Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ {pair}")
        
        try:
            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±
            htf_df = await self.get_market_data_async(pair, HIGH_TIMEFRAME)
            ltf_df = await self.get_market_data_async(pair, LOW_TIMEFRAME)
            
            if htf_df is None or ltf_df is None or htf_df.empty or ltf_df.empty:
                logging.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ {pair} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª")
                return None
            
            # ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
            htf_df_processed = self.technical_analyzer.calculate_advanced_indicators(htf_df)
            ltf_df_processed = self.technical_analyzer.calculate_advanced_indicators(ltf_df)
            
            if htf_df_processed is None or ltf_df_processed is None:
                logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ {pair}")
                return None
            
            technical_analysis = self.technical_analyzer.generate_technical_analysis(pair, htf_df_processed, ltf_df_processed)
            
            if not technical_analysis:
                logging.warning(f"ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø¨Ø±Ø§ÛŒ {pair} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")
                return None
            
            # ØªØ­Ù„ÛŒÙ„ Ú†Ù‡Ø§Ø±Ú¯Ø§Ù†Ù‡ AI
            ai_analysis = await self.ai_manager.get_quad_analysis(pair, technical_analysis)
            
            if ai_analysis and ai_analysis.get('ACTION') != 'HOLD':
                self.cache_manager.update_cache(pair, ai_analysis)
                logging.info(f"âœ… Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø¨Ø±Ø§ÛŒ {pair}: {ai_analysis['ACTION']} (ØªÙˆØ§ÙÙ‚: {ai_analysis.get('AGREEMENT_LEVEL', 0)}/5)")
                return ai_analysis
            else:
                logging.info(f"ğŸ” Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø¨Ø±Ø§ÛŒ {pair} Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯")
                return None
                
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ {pair}: {e}")
            return None

    async def get_market_data_async(self, symbol: str, interval: str, retries: int = 3) -> Optional[pd.DataFrame]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø¨Ù‡ ØµÙˆØ±Øª Ø¢Ø³Ù†Ú©Ø±ÙˆÙ†"""
        for attempt in range(retries):
            try:
                async with self.api_rate_limiter:
                    url = f'https://api.twelvedata.com/time_series?symbol={symbol}&interval={interval}&outputsize={CANDLES_TO_FETCH}&apikey={TWELVEDATA_API_KEY}'
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, timeout=60) as response:
                            if response.status == 200:
                                data = await response.json()
                                if 'values' in data and data['values']:
                                    df = pd.DataFrame(data['values'])
                                    df = df.iloc[::-1].reset_index(drop=True)
                                    
                                    numeric_columns = ['open', 'high', 'low', 'close']
                                    for col in numeric_columns:
                                        if col in df.columns:
                                            df[col] = pd.to_numeric(df[col], errors='coerce')
                                    
                                    if 'datetime' in df.columns:
                                        df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')
                                    
                                    df = df.dropna(subset=numeric_columns)
                                    
                                    if len(df) > 0:
                                        return df
                                    else:
                                        logging.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol} Ù¾Ø³ Ø§Ø² Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª")
                                        return None
                                else:
                                    logging.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol} Ø®Ø§Ù„ÛŒ Ø§Ø³Øª ÛŒØ§ Ø³Ø§Ø®ØªØ§Ø± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¯Ø§Ø±Ø¯")
                                    return None
                            else:
                                logging.warning(f"Ø®Ø·Ø§ÛŒ HTTP {response.status} Ø¨Ø±Ø§ÛŒ {symbol}")
                                if response.status == 429:
                                    await asyncio.sleep(10)
                                
            except Exception as e:
                logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol} (ØªÙ„Ø§Ø´ {attempt + 1}): {e}")
                await asyncio.sleep(2)
        
        logging.error(f"Ø¹Ø¯Ù… Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol} Ù¾Ø³ Ø§Ø² {retries} ØªÙ„Ø§Ø´")
        return None

    async def analyze_all_pairs(self, pairs: List[str]) -> List[Dict]:
        """ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ù‡ Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…ÙˆØ§Ø²ÛŒ"""
        logging.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ {len(pairs)} Ø¬ÙØª Ø§Ø±Ø²")
        
        semaphore = asyncio.Semaphore(2)
        
        async def bounded_analyze(pair):
            async with semaphore:
                result = await self.analyze_pair(pair)
                await asyncio.sleep(1)
                return result
        
        tasks = [bounded_analyze(pair) for pair in pairs]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        valid_signals = []
        for result in results:
            if isinstance(result, Dict) and result.get('ACTION') != 'HOLD':
                valid_signals.append(result)
            elif isinstance(result, Exception):
                logging.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„: {result}")
        
        logging.info(f"ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯. {len(valid_signals)} Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹ØªØ¨Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯")
        return valid_signals

# =================================================================================
# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ---
# =================================================================================

async def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡"""
    logging.info("ğŸ¯ Ø´Ø±ÙˆØ¹ Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ ÙØ§Ø±Ú©Ø³ Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Quad AI v4.0)")
    
    import argparse
    parser = argparse.ArgumentParser(description='Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ ÙØ§Ø±Ú©Ø³ Ø¨Ø§ AI Ú†Ù‡Ø§Ø±Ú¯Ø§Ù†Ù‡')
    parser.add_argument("--pair", type=str, help="ØªØ­Ù„ÛŒÙ„ Ø¬ÙØª Ø§Ø±Ø² Ù…Ø´Ø®Øµ (Ù…Ø«Ø§Ù„: EUR/USD)")
    parser.add_argument("--all", action="store_true", help="ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ù‡ Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶")
    parser.add_argument("--pairs", type=str, help="ØªØ­Ù„ÛŒÙ„ Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ (Ø¬Ø¯Ø§ Ø´Ø¯Ù‡ Ø¨Ø§ Ú©Ø§Ù…Ø§)")
    
    args = parser.parse_args()

    if args.pair:
        pairs_to_analyze = [args.pair]
    elif args.pairs:
        pairs_to_analyze = [p.strip() for p in args.pairs.split(',')]
    elif args.all:
        pairs_to_analyze = CURRENCY_PAIRS_TO_ANALYZE
    else:
        pairs_to_analyze = CURRENCY_PAIRS_TO_ANALYZE[:5]
        logging.info(f"Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 5 Ø¬ÙØª Ø§Ø±Ø² Ø§ØµÙ„ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶")

    logging.info(f"ğŸ” Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„: {', '.join(pairs_to_analyze)}")
    
    analyzer = AdvancedForexAnalyzer()
    signals = await analyzer.analyze_all_pairs(pairs_to_analyze)

    # ØªÙ‚Ø³ÛŒÙ… Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø·Ø­ ØªÙˆØ§ÙÙ‚
    strong_consensus_signals = []    # 3-4 Ù…ÙˆØ§ÙÙ‚
    weak_consensus_signals = []      # 2 Ù…ÙˆØ§ÙÙ‚  
    no_consensus_signals = []        # 0-1 Ù…ÙˆØ§ÙÙ‚
    
    for signal in signals:
        agreement_level = signal.get('AGREEMENT_LEVEL', 0)
        if agreement_level >= 3:
            strong_consensus_signals.append(signal)
        elif agreement_level == 2:
            weak_consensus_signals.append(signal)
        else:
            no_consensus_signals.append(signal)

    # Ø°Ø®ÛŒØ±Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ ØªÙˆØ§ÙÙ‚ Ù‚ÙˆÛŒ
    if strong_consensus_signals:
        strong_conf_file = "strong_consensus_signals.json"
        cleaned_strong_signals = []
        
        for signal in strong_consensus_signals:
            cleaned_signal = {
                'SYMBOL': signal.get('SYMBOL', 'Unknown'),
                'ACTION': signal.get('ACTION', 'HOLD'),
                'CONFIDENCE': signal.get('CONFIDENCE', 0),
                'AGREEMENT_LEVEL': signal.get('AGREEMENT_LEVEL', 0),
                'VALID_MODELS': signal.get('VALID_MODELS', 0),
                'AGREEMENT_TYPE': signal.get('AGREEMENT_TYPE', 'UNKNOWN'),
                'PRIORITY': signal.get('PRIORITY', 'MEDIUM'),
                'ENTRY_ZONE': signal.get('ENTRY_ZONE', 'N/A'),
                'STOP_LOSS': signal.get('STOP_LOSS', 'N/A'),
                'TAKE_PROFIT_1': signal.get('TAKE_PROFIT_1', 'N/A'),
                'TAKE_PROFIT_2': signal.get('TAKE_PROFIT_2', 'N/A'),
                'RISK_REWARD_RATIO': signal.get('RISK_REWARD_RATIO', 'N/A'),
                'EXPIRATION_H': signal.get('EXPIRATION_H', 0),
                'CONSENSUS_ANALYSIS': signal.get('CONSENSUS_ANALYSIS', ''),
                'TIMESTAMP': signal.get('timestamp', datetime.now(UTC).isoformat())
            }
            cleaned_strong_signals.append(cleaned_signal)
        
        with open(strong_conf_file, 'w', encoding='utf-8') as f:
            json.dump(cleaned_strong_signals, f, indent=4, ensure_ascii=False)
        
        logging.info(f"âœ… {len(strong_consensus_signals)} Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ ØªÙˆØ§ÙÙ‚ Ù‚ÙˆÛŒ Ø¯Ø± {strong_conf_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

    # Ø°Ø®ÛŒØ±Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ ØªÙˆØ§ÙÙ‚ Ø¶Ø¹ÛŒÙ
    if weak_consensus_signals:
        weak_conf_file = "weak_consensus_signals.json"
        cleaned_weak_signals = []
        
        for signal in weak_consensus_signals:
            cleaned_signal = {
                'SYMBOL': signal.get('SYMBOL', 'Unknown'),
                'ACTION': signal.get('ACTION', 'HOLD'),
                'CONFIDENCE': signal.get('CONFIDENCE', 0),
                'AGREEMENT_LEVEL': signal.get('AGREEMENT_LEVEL', 0),
                'VALID_MODELS': signal.get('VALID_MODELS', 0),
                'AGREEMENT_TYPE': signal.get('AGREEMENT_TYPE', 'UNKNOWN'),
                'PRIORITY': signal.get('PRIORITY', 'MEDIUM'),
                'ENTRY_ZONE': signal.get('ENTRY_ZONE', 'N/A'),
                'STOP_LOSS': signal.get('STOP_LOSS', 'N/A'),
                'TAKE_PROFIT_1': signal.get('TAKE_PROFIT_1', 'N/A'),
                'TAKE_PROFIT_2': signal.get('TAKE_PROFIT_2', 'N/A'),
                'RISK_REWARD_RATIO': signal.get('RISK_REWARD_RATIO', 'N/A'),
                'EXPIRATION_H': signal.get('EXPIRATION_H', 0),
                'CONSENSUS_ANALYSIS': signal.get('CONSENSUS_ANALYSIS', ''),
                'TIMESTAMP': signal.get('timestamp', datetime.now(UTC).isoformat())
            }
            cleaned_weak_signals.append(cleaned_signal)
        
        with open(weak_conf_file, 'w', encoding='utf-8') as f:
            json.dump(cleaned_weak_signals, f, indent=4, ensure_ascii=False)
        
        logging.info(f"ğŸ“Š {len(weak_consensus_signals)} Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ ØªÙˆØ§ÙÙ‚ Ø¶Ø¹ÛŒÙ Ø¯Ø± {weak_conf_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

    # Ø°Ø®ÛŒØ±Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ§ÙÙ‚
    if no_consensus_signals:
        no_conf_file = "no_consensus_signals.json"
        cleaned_no_signals = []
        
        for signal in no_consensus_signals:
            cleaned_signal = {
                'SYMBOL': signal.get('SYMBOL', 'Unknown'),
                'ACTION': signal.get('ACTION', 'HOLD'),
                'CONFIDENCE': signal.get('CONFIDENCE', 0),
                'AGREEMENT_LEVEL': signal.get('AGREEMENT_LEVEL', 0),
                'VALID_MODELS': signal.get('VALID_MODELS', 0),
                'AGREEMENT_TYPE': signal.get('AGREEMENT_TYPE', 'UNKNOWN'),
                'PRIORITY': signal.get('PRIORITY', 'LOW'),
                'ENTRY_ZONE': signal.get('ENTRY_ZONE', 'N/A'),
                'STOP_LOSS': signal.get('STOP_LOSS', 'N/A'),
                'TAKE_PROFIT_1': signal.get('TAKE_PROFIT_1', 'N/A'),
                'TAKE_PROFIT_2': signal.get('TAKE_PROFIT_2', 'N/A'),
                'RISK_REWARD_RATIO': signal.get('RISK_REWARD_RATIO', 'N/A'),
                'EXPIRATION_H': signal.get('EXPIRATION_H', 0),
                'CONSENSUS_ANALYSIS': signal.get('CONSENSUS_ANALYSIS', ''),
                'TIMESTAMP': signal.get('timestamp', datetime.now(UTC).isoformat())
            }
            cleaned_no_signals.append(cleaned_signal)
        
        with open(no_conf_file, 'w', encoding='utf-8') as f:
            json.dump(cleaned_no_signals, f, indent=4, ensure_ascii=False)
        
        logging.info(f"âš ï¸ {len(no_consensus_signals)} Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø¯ÙˆÙ† ØªÙˆØ§ÙÙ‚ Ø¯Ø± {no_conf_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

    # Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬
    logging.info("ğŸ“ˆ Ø®Ù„Ø§ØµÙ‡ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ:")
    
    logging.info("ğŸ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ ØªÙˆØ§ÙÙ‚ Ù‚ÙˆÛŒ (3-4 Ù…Ø¯Ù„ Ù…ÙˆØ§ÙÙ‚):")
    for signal in strong_consensus_signals:
        action_icon = "ğŸŸ¢" if signal['ACTION'] == 'BUY' else "ğŸ”´" if signal['ACTION'] == 'SELL' else "âšª"
        logging.info(f"  {action_icon} {signal['SYMBOL']}: {signal['ACTION']} (Ø§Ø¹ØªÙ…Ø§Ø¯: {signal['CONFIDENCE']}/10, ØªÙˆØ§ÙÙ‚: {signal['AGREEMENT_LEVEL']}/5)")
    
    logging.info("ğŸ“Š Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ ØªÙˆØ§ÙÙ‚ Ø¶Ø¹ÛŒÙ (2 Ù…Ø¯Ù„ Ù…ÙˆØ§ÙÙ‚):")
    for signal in weak_consensus_signals:
        action_icon = "ğŸŸ¢" if signal['ACTION'] == 'BUY' else "ğŸ”´" if signal['ACTION'] == 'SELL' else "âšª"
        logging.info(f"  {action_icon} {signal['SYMBOL']}: {signal['ACTION']} (Ø§Ø¹ØªÙ…Ø§Ø¯: {signal['CONFIDENCE']}/10, ØªÙˆØ§ÙÙ‚: {signal['AGREEMENT_LEVEL']}/5)")
    
    logging.info("âš ï¸ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ§ÙÙ‚ (0-1 Ù…Ø¯Ù„ Ù…ÙˆØ§ÙÙ‚):")
    for signal in no_consensus_signals:
        action_icon = "ğŸŸ¢" if signal['ACTION'] == 'BUY' else "ğŸ”´" if signal['ACTION'] == 'SELL' else "âšª"
        logging.info(f"  {action_icon} {signal['SYMBOL']}: {signal['ACTION']} (Ø§Ø¹ØªÙ…Ø§Ø¯: {signal['CONFIDENCE']}/10, ØªÙˆØ§ÙÙ‚: {signal['AGREEMENT_LEVEL']}/5)")

    if not signals:
        logging.info("ğŸ” Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒâ€ŒØ§ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ø§Ø¬Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯")

    logging.info("ğŸ Ù¾Ø§ÛŒØ§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…")

if __name__ == "__main__":
    asyncio.run(main())
