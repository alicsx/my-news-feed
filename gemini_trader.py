import google.generativeai as genai
import os
import re
import time
import json
import logging
import pandas as pd
import pandas_ta as ta
import requests
from datetime import datetime, timedelta, UTC
import aiohttp
import asyncio
from typing import Dict, List, Optional, Tuple
import concurrent.futures

# =================================================================================
# --- Ø¨Ø®Ø´ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ---
# =================================================================================

# Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API
google_api_key = os.getenv("GOOGLE_API_KEY")
TWELVEDATA_API_KEY = os.getenv("TWELVEDATA_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

if not all([google_api_key, TWELVEDATA_API_KEY]):
    raise ValueError("Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯: GOOGLE_API_KEY, TWELVEDATA_API_KEY")

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ Ø³ÛŒØ³ØªÙ…
HIGH_TIMEFRAME = "4h"
LOW_TIMEFRAME = "1h"
CANDLES_TO_FETCH = 300
CURRENCY_PAIRS_TO_ANALYZE = [
    "EUR/USD", "GBP/USD", "USD/JPY", "USD/CHF", "AUD/USD",
    "GBP/JPY", "EUR/JPY", "AUD/JPY", "NZD/USD", "USD/CAD",
    "EUR/GBP", "AUD/NZD", "EUR/AUD", "GBP/CHF", "CAD/JPY"
]

CACHE_FILE = "signal_cache.json"
CACHE_DURATION_HOURS = 2  # Ù…Ù†Ø·Ø¨Ù‚ Ø¨Ø§ Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ø± 2 Ø³Ø§Ø¹Øª
LOG_FILE = "trading_log.log"

# Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI
GEMINI_MODEL = 'gemini-1.5-flash-latest'  # Ø³Ø±ÛŒØ¹â€ŒØªØ± Ùˆ Ø§Ù‚ØªØµØ§Ø¯ÛŒâ€ŒØªØ±
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"

# Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ… Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# =================================================================================
# --- Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯ ---
# =================================================================================

class SmartCacheManager:
    def __init__(self, cache_file: str, cache_duration_hours: int):
        self.cache_file = cache_file
        self.cache_duration_hours = cache_duration_hours
        self.cache = self.load_cache()
        
    def load_cache(self) -> Dict:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø´ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø² Ø®Ø·Ø§"""
        if not os.path.exists(self.cache_file):
            return {}
        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache = json.load(f)
                # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ú©Ø´â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
                return self.clean_old_cache(cache)
        except (json.JSONDecodeError, IOError) as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø´: {e}")
            return {}
    
    def clean_old_cache(self, cache: Dict) -> Dict:
        """Ø­Ø°Ù ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø² Ú©Ø´"""
        cleaned_cache = {}
        current_time = datetime.now(UTC)
        
        for pair, cache_data in cache.items():
            if isinstance(cache_data, str):
                # ÙØ±Ù…Øª Ù‚Ø¯ÛŒÙ…ÛŒ
                last_signal_time = datetime.fromisoformat(cache_data)
                if current_time - last_signal_time < timedelta(hours=self.cache_duration_hours):
                    cleaned_cache[pair] = cache_data
            elif isinstance(cache_data, dict):
                # ÙØ±Ù…Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„
                signal_time = datetime.fromisoformat(cache_data.get('timestamp', ''))
                if current_time - signal_time < timedelta(hours=self.cache_duration_hours):
                    cleaned_cache[pair] = cache_data
                    
        return cleaned_cache
    
    def is_pair_on_cooldown(self, pair: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª cooldown Ø¨Ø±Ø§ÛŒ Ø¬ÙØª Ø§Ø±Ø²"""
        if pair not in self.cache:
            return False
            
        cache_data = self.cache[pair]
        if isinstance(cache_data, str):
            last_signal_time = datetime.fromisoformat(cache_data)
        else:
            last_signal_time = datetime.fromisoformat(cache_data.get('timestamp', ''))
            
        if datetime.now(UTC) - last_signal_time < timedelta(hours=self.cache_duration_hours):
            logging.info(f"Ø¬ÙØª Ø§Ø±Ø² {pair} Ø¯Ø± Ø¯ÙˆØ±Ù‡ Ø§Ø³ØªØ±Ø§Ø­Øª Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯")
            return True
        return False
    
    def update_cache(self, pair: str, signal_data: Dict = None):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©Ø´ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„"""
        self.cache[pair] = {
            'timestamp': datetime.now(UTC).isoformat(),
            'signal': signal_data or {}
        }
        self.save_cache()
    
    def save_cache(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ø§ÛŒÙ…Ù† Ú©Ø´"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, indent=4, ensure_ascii=False)
        except IOError as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ú©Ø´: {e}")

# =================================================================================
# --- Ú©Ù„Ø§Ø³ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ---
# =================================================================================

class AdvancedTechnicalAnalyzer:
    def __init__(self):
        self.indicators_config = {
            'trend': ['ema_21', 'ema_50', 'ema_200', 'adx_14'],
            'momentum': ['rsi_14', 'stoch_14_3_3', 'macd'],
            'volatility': ['bb_20_2', 'atr_14'],
            'volume': ['obv', 'volume_sma_20'],
            'ichimoku': True,
            'support_resistance': True,
            'candle_patterns': True
        }
    
    def calculate_advanced_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§"""
        if df is None or df.empty or len(df) < 100:
            return None
            
        try:
            # Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ø±ÙˆÙ†Ø¯
            df.ta.ema(length=21, append=True)
            df.ta.ema(length=50, append=True)
            df.ta.ema(length=200, append=True)
            df.ta.adx(length=14, append=True)
            
            # Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù…ÙˆÙ…Ù†ØªÙˆÙ…
            df.ta.rsi(length=14, append=True)
            df.ta.stoch(append=True)
            df.ta.macd(append=True)
            
            # Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù†ÙˆØ³Ø§Ù†
            df.ta.bbands(length=20, std=2, append=True)
            df.ta.atr(length=14, append=True)
            
            # Ø­Ø¬Ù…
            if 'volume' in df.columns and not df['volume'].isnull().all():
                logging.info(f"Ø³ØªÙˆÙ† 'volume' Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ø­Ø¬Ù…...")
                df.ta.obv(append=True)
                df['volume_sma_20'] = df['volume'].rolling(20).mean()
            else:
                logging.warning("Ø³ØªÙˆÙ† 'volume' Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ OBV Ùˆ Volume SMA Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù†Ø¯.")
            
            # Ø§ÛŒÚ†ÛŒÙ…ÙˆÚ©Ùˆ
            df.ta.ichimoku(append=True)
            
            # Ø³Ø·ÙˆØ­ Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª
            df['sup_1'] = df['low'].rolling(20).min().shift(1)
            df['res_1'] = df['high'].rolling(20).max().shift(1)
            df['sup_2'] = df['low'].rolling(50).min().shift(1)
            df['res_2'] = df['high'].rolling(50).max().shift(1)
            
            # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©
            if self.indicators_config['candle_patterns']:
                popular_patterns = ['doji', 'hammer', 'engulfing', 'harami', 'morning_star', 'evening_star']
                for pattern in popular_patterns:
                    try:
                        df.ta.cdl_pattern(pattern, append=True)
                    except:
                        continue
            
            df.dropna(inplace=True)
            return df
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§: {e}")
            return None
    
    def generate_technical_analysis(self, symbol: str, htf_df: pd.DataFrame, ltf_df: pd.DataFrame) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø¬Ø§Ù…Ø¹"""
        if htf_df.empty or ltf_df.empty:
            return None
            
        last_htf = htf_df.iloc[-1]
        last_ltf = ltf_df.iloc[-1]
        prev_ltf = ltf_df.iloc[-2] if len(ltf_df) > 1 else last_ltf
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯
        htf_trend = self._analyze_trend(last_htf)
        ltf_trend = self._analyze_trend(last_ltf)
        
        # ØªØ­Ù„ÛŒÙ„ Ù…ÙˆÙ…Ù†ØªÙˆÙ…
        momentum = self._analyze_momentum(last_ltf)
        
        # ØªØ­Ù„ÛŒÙ„ Ø³Ø·ÙˆØ­ Ú©Ù„ÛŒØ¯ÛŒ
        key_levels = self._analyze_key_levels(htf_df, ltf_df, last_ltf['close'])
        
        # ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©
        candle_analysis = self._analyze_candle_patterns(ltf_df)
        
        return {
            'symbol': symbol,
            'htf_trend': htf_trend,
            'ltf_trend': ltf_trend,
            'momentum': momentum,
            'key_levels': key_levels,
            'candle_patterns': candle_analysis,
            'volatility': last_ltf.get('ATRr_14', 0),
            'timestamp': datetime.now(UTC).isoformat()
        }
    
    def _analyze_trend(self, data: pd.Series) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§"""
        ema_21 = data.get('EMA_21', 0)
        ema_50 = data.get('EMA_50', 0)
        ema_200 = data.get('EMA_200', 0)
        adx = data.get('ADX_14', 0)
        
        trend_direction = "ØµØ¹ÙˆØ¯ÛŒ" if ema_21 > ema_50 > ema_200 else "Ù†Ø²ÙˆÙ„ÛŒ" if ema_21 < ema_50 < ema_200 else "Ø®Ù†Ø«ÛŒ"
        trend_strength = "Ù‚ÙˆÛŒ" if adx > 25 else "Ø¶Ø¹ÛŒÙ" if adx < 20 else "Ù…ØªÙˆØ³Ø·"
        
        return {
            'direction': trend_direction,
            'strength': trend_strength,
            'adx': adx,
            'ema_alignment': f"EMA21: {ema_21:.5f}, EMA50: {ema_50:.5f}, EMA200: {ema_200:.5f}"
        }
    
    def _analyze_momentum(self, data: pd.Series) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ù…ÙˆÙ…Ù†ØªÙˆÙ…"""
        rsi = data.get('RSI_14', 50)
        macd_hist = data.get('MACDh_12_26_9', 0)
        stoch_k = data.get('STOCHk_14_3_3', 50)
        
        rsi_signal = "Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯" if rsi > 70 else "Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´" if rsi < 30 else "Ø®Ù†Ø«ÛŒ"
        macd_signal = "ØµØ¹ÙˆØ¯ÛŒ" if macd_hist > 0 else "Ù†Ø²ÙˆÙ„ÛŒ"
        stoch_signal = "Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯" if stoch_k > 80 else "Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´" if stoch_k < 20 else "Ø®Ù†Ø«ÛŒ"
        
        return {
            'rsi': {'value': rsi, 'signal': rsi_signal},
            'macd': {'signal': macd_signal, 'histogram': macd_hist},
            'stochastic': {'value': stoch_k, 'signal': stoch_signal}
        }
    
    def _analyze_key_levels(self, htf_df: pd.DataFrame, ltf_df: pd.DataFrame, current_price: float) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø³Ø·ÙˆØ­ Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª"""
        # Ø³Ø·ÙˆØ­ Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ© Ø§Ø² Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±
        bb_upper = ltf_df['BBU_20_2.0'].iloc[-1]
        bb_lower = ltf_df['BBL_20_2.0'].iloc[-1]
        bb_middle = ltf_df['BBM_20_2.0'].iloc[-1]
        
        # Ø³Ø·ÙˆØ­ Ø§Ø³ØªØ§ØªÛŒÚ©
        support_1 = ltf_df['sup_1'].iloc[-1]
        resistance_1 = ltf_df['res_1'].iloc[-1]
        support_2 = ltf_df['sup_2'].iloc[-1]
        resistance_2 = ltf_df['res_2'].iloc[-1]
        
        return {
            'dynamic': {
                'bb_upper': bb_upper,
                'bb_lower': bb_lower,
                'bb_middle': bb_middle
            },
            'static': {
                'support_1': support_1,
                'resistance_1': resistance_1,
                'support_2': support_2,
                'resistance_2': resistance_2
            },
            'current_price_position': self._get_price_position(current_price, support_1, resistance_1)
        }
    
    def _get_price_position(self, price: float, support: float, resistance: float) -> str:
        """ØªØ¹ÛŒÛŒÙ† Ù…ÙˆÙ‚Ø¹ÛŒØª Ù‚ÛŒÙ…Øª Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø³Ø·ÙˆØ­"""
        range_size = resistance - support
        if range_size == 0:
            return "Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø®Ù†Ø«ÛŒ"
        
        position = (price - support) / range_size
        if position < 0.3:
            return "Ù†Ø²Ø¯ÛŒÚ© Ø­Ù…Ø§ÛŒØª"
        elif position > 0.7:
            return "Ù†Ø²Ø¯ÛŒÚ© Ù…Ù‚Ø§ÙˆÙ…Øª"
        else:
            return "Ø¯Ø± Ù…ÛŒØ§Ù†Ù‡ Ø±Ù†Ø¬"
    
    def _analyze_candle_patterns(self, df: pd.DataFrame) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©"""
        if len(df) < 3:
            return {}
            
        last_candle = df.iloc[-1]
        patterns = []
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø­Ø¨ÙˆØ¨
        candle_indicators = [col for col in df.columns if col.startswith('CDL_')]
        for indicator in candle_indicators:
            if abs(last_candle.get(indicator, 0)) > 0:
                pattern_name = indicator.replace('CDL_', '')
                direction = "ØµØ¹ÙˆØ¯ÛŒ" if last_candle[indicator] > 0 else "Ù†Ø²ÙˆÙ„ÛŒ"
                patterns.append(f"{pattern_name} ({direction})")
        
        # ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ú©Ù†Ø¯Ù„ ÙØ¹Ù„ÛŒ
        current_candle = self._analyze_single_candle(df.iloc[-1])
        
        return {
            'patterns': patterns,
            'current_candle': current_candle,
            'recent_patterns': patterns[-3:] if patterns else []
        }
    
    def _analyze_single_candle(self, candle: pd.Series) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ ØªÚ© Ú©Ù†Ø¯Ù„"""
        open_price = candle['open']
        close = candle['close']
        high = candle['high']
        low = candle['low']
        
        body_size = abs(close - open_price)
        total_range = high - low
        
        if total_range == 0:
            return {"type": "ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡"}
            
        body_ratio = body_size / total_range
        
        if body_ratio < 0.3:
            candle_type = "Ø¯ÙˆØ¬ÛŒ/ÙØ±ÙØ±Ù‡"
        elif body_ratio > 0.7:
            candle_type = "Ù…Ø§Ø±ÙˆØ¨ÙˆØ²Ùˆ"
        else:
            candle_type = "Ø¹Ø§Ø¯ÛŒ"
            
        direction = "ØµØ¹ÙˆØ¯ÛŒ" if close > open_price else "Ù†Ø²ÙˆÙ„ÛŒ"
        
        return {
            'type': candle_type,
            'direction': direction,
            'body_ratio': body_ratio,
            'strength': "Ù‚ÙˆÛŒ" if body_ratio > 0.6 else "Ù…ØªÙˆØ³Ø·" if body_ratio > 0.3 else "Ø¶Ø¹ÛŒÙ"
        }

# =================================================================================
# --- Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª AI ØªØ±Ú©ÛŒØ¨ÛŒ ---
# =================================================================================

class HybridAIManager:
    def __init__(self, gemini_api_key: str, deepseek_api_key: str):
        self.gemini_api_key = gemini_api_key
        self.deepseek_api_key = deepseek_api_key
        self.gemini_model = GEMINI_MODEL
        self.deepseek_url = DEEPSEEK_API_URL
        
        # ØªÙ†Ø¸ÛŒÙ… Gemini
        genai.configure(api_key=gemini_api_key)
    
    async def get_combined_analysis(self, symbol: str, technical_analysis: Dict) -> Optional[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ ØªØ±Ú©ÛŒØ¨ÛŒ Ø§Ø² Ø¯Ùˆ Ù…Ø¯Ù„ AI"""
        tasks = [
            self._get_gemini_analysis(symbol, technical_analysis),
            self._get_deepseek_analysis(symbol, technical_analysis)
        ]
        
        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            gemini_result, deepseek_result = results
            
            return self._combine_analyses(symbol, gemini_result, deepseek_result, technical_analysis)
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return None
    
    async def _get_gemini_analysis(self, symbol: str, technical_analysis: Dict) -> Optional[Dict]:
        """ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Gemini"""
        try:
            prompt = self._create_analysis_prompt(symbol, technical_analysis, "Gemini")
            model = genai.GenerativeModel(self.gemini_model)
            
            response = await asyncio.to_thread(
                model.generate_content,
                prompt,
                request_options={'timeout': 120}
            )
            
            return self._parse_ai_response(response.text, symbol, "Gemini")
            
        except Exception as e:
            logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Gemini Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return None
    
    async def _get_deepseek_analysis(self, symbol: str, technical_analysis: Dict) -> Optional[Dict]:
        """ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ DeepSeek"""
        if not self.deepseek_api_key:
            logging.warning("Ú©Ù„ÛŒØ¯ DeepSeek API ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
            return None
            
        try:
            prompt = self._create_analysis_prompt(symbol, technical_analysis, "DeepSeek")
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.deepseek_api_key}"
            }
            
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": "You are an expert forex trading analyst."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.3,
                "max_tokens": 1500
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(self.deepseek_url, headers=headers, json=payload, timeout=120) as response:
                    if response.status == 200:
                        data = await response.json()
                        content = data["choices"][0]["message"]["content"]
                        return self._parse_ai_response(content, symbol, "DeepSeek")
                    else:
                        logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø³Ø® DeepSeek: {response.status}")
                        return None
                        
        except Exception as e:
            logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ DeepSeek Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return None
    
    def _create_analysis_prompt(self, symbol: str, technical_analysis: Dict, ai_name: str) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø±Ù…Ù¾Øª ØªØ­Ù„ÛŒÙ„"""
        base_currency, quote_currency = symbol.split('/')
        
        return f"""
Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§Ø²Ø§Ø± ÙØ§Ø±Ú©Ø³ØŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø²ÛŒØ± Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¬ÙØª Ø§Ø±Ø² {symbol} Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯:

ğŸ“Š **ÙˆØ¶Ø¹ÛŒØª ØªÚ©Ù†ÛŒÚ©Ø§Ù„ {symbol}:**
- Ø±ÙˆÙ†Ø¯ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª (HTF): {technical_analysis['htf_trend']['direction']} - Ù‚Ø¯Ø±Øª: {technical_analysis['htf_trend']['strength']}
- Ø±ÙˆÙ†Ø¯ Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª (LTF): {technical_analysis['ltf_trend']['direction']}
- Ù…ÙˆÙ…Ù†ØªÙˆÙ…: RSI {technical_analysis['momentum']['rsi']['value']:.1f} ({technical_analysis['momentum']['rsi']['signal']})
- Ù…ÙˆÙ‚Ø¹ÛŒØª Ù‚ÛŒÙ…Øª: {technical_analysis['key_levels']['current_price_position']}

ğŸ¯ **Ø³Ø·ÙˆØ­ Ú©Ù„ÛŒØ¯ÛŒ:**
- Ù…Ù‚Ø§ÙˆÙ…Øª Û±: {technical_analysis['key_levels']['static']['resistance_1']:.5f}
- Ø­Ù…Ø§ÛŒØª Û±: {technical_analysis['key_levels']['static']['support_1']:.5f}
- Ù…Ù‚Ø§ÙˆÙ…Øª Û²: {technical_analysis['key_levels']['static']['resistance_2']:.5f}
- Ø­Ù…Ø§ÛŒØª Û²: {technical_analysis['key_levels']['static']['support_2']:.5f}

ğŸ•¯ï¸ **Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ÛŒ:**
{chr(10).join(technical_analysis['candle_patterns']['patterns'][-3:]) if technical_analysis['candle_patterns']['patterns'] else 'Ø§Ù„Ú¯ÙˆÛŒ Ø®Ø§ØµÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯'}

**Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹ØªØ¨Ø±ØŒ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†ÛŒØ¯:**

```json
{{
  "SYMBOL": "{symbol}",
  "ACTION": "BUY/SELL/HOLD",
  "CONFIDENCE": 1-10,
  "ENTRY_ZONE": "Ù…Ø­Ø¯ÙˆØ¯Ù‡ ÙˆØ±ÙˆØ¯",
  "STOP_LOSS": "Ø­Ø¯ Ø¶Ø±Ø±",
  "TAKE_PROFIT": "Ø­Ø¯ Ø³ÙˆØ¯", 
  "RISK_REWARD_RATIO": "Ù†Ø³Ø¨Øª risk/reward",
  "ANALYSIS": "ØªØ­Ù„ÛŒÙ„ Ú©Ù„ÛŒ ÙˆØ¶Ø¹ÛŒØª"
}}
Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙˆØ§Ø¶Ø­ØŒ Ø§Ø² ACTION: "HOLD" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.
"""
def _parse_ai_response(self, response: str, symbol: str, ai_name: str) -> Optional[Dict]:
    """Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø® AI"""
    try:
        # Ø¬Ø³ØªØ¬ÙˆÛŒ JSON Ø¯Ø± Ù¾Ø§Ø³Ø®
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
        if not json_match:
            json_match = re.search(r'(\{.*?\})', response, re.DOTALL)
        
        if json_match:
            json_str = json_match.group(1)
            signal_data = json.loads(json_str)
            
            # Ø§ÙØ²ÙˆØ¯Ù† Ù…ØªØ§ Ø¯ÛŒØªØ§
            signal_data['ai_model'] = ai_name
            signal_data['timestamp'] = datetime.now(UTC).isoformat()
            
            logging.info(f"âœ… {ai_name} Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ {symbol}: {signal_data.get('ACTION', 'HOLD')}")
            return signal_data
        else:
            logging.warning(f"âŒ Ù¾Ø§Ø³Ø® {ai_name} Ø¨Ø±Ø§ÛŒ {symbol} ÙØ§Ù‚Ø¯ ÙØ±Ù…Øª JSON Ø¨ÙˆØ¯")
            return None
            
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø® {ai_name} Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
        return None

def _combine_analyses(self, symbol: str, gemini_result: Dict, deepseek_result: Dict, technical_analysis: Dict) -> Optional[Dict]:
    """ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬ Ø¯Ùˆ Ù…Ø¯Ù„ AI"""
    results = []
    
    if gemini_result and gemini_result.get('ACTION') != 'HOLD':
        results.append(('Gemini', gemini_result))
    if deepseek_result and deepseek_result.get('ACTION') != 'HOLD':
        results.append(('DeepSeek', deepseek_result))
    
    if not results:
        logging.info(f"Ù‡Ø± Ø¯Ùˆ Ù…Ø¯Ù„ AI Ø¨Ø±Ø§ÛŒ {symbol} Ø³ÛŒÚ¯Ù†Ø§Ù„ HOLD Ø¯Ø§Ø¯Ù†Ø¯")
        return {
            'SYMBOL': symbol,
            'ACTION': 'HOLD',
            'CONFIDENCE': 0,
            'COMBINED_ANALYSIS': True,
            'MODELS_AGREE': True,
            'ANALYSIS': 'Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙˆØ§Ø¶Ø­ Ø§Ø² Ù‡Ø± Ø¯Ùˆ Ù…Ø¯Ù„'
        }
    
    # Ø§Ú¯Ø± ÙÙ‚Ø· ÛŒÚ© Ù…Ø¯Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¯Ø§Ø¯
    if len(results) == 1:
        model_name, result = results[0]
        result['COMBINED_ANALYSIS'] = True
        result['MODELS_AGREE'] = False
        result['CONFIDENCE'] = max(1, result.get('CONFIDENCE', 5) - 2)  # Ú©Ø§Ù‡Ø´ Ø§Ø¹ØªÙ…Ø§Ø¯
        result['ANALYSIS'] = f"Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø§Ø² {model_name} - Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ£ÛŒÛŒØ¯ Ø¨ÛŒØ´ØªØ±"
        return result
    
    # Ø§Ú¯Ø± Ù‡Ø± Ø¯Ùˆ Ù…Ø¯Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¯Ø§Ø¯Ù†Ø¯
    gemini_action = gemini_result.get('ACTION')
    deepseek_action = deepseek_result.get('ACTION')
    
    if gemini_action == deepseek_action:
        # ØªÙˆØ§ÙÙ‚ Ú©Ø§Ù…Ù„
        combined_confidence = (gemini_result.get('CONFIDENCE', 5) + deepseek_result.get('CONFIDENCE', 5)) // 2
        return {
            'SYMBOL': symbol,
            'ACTION': gemini_action,
            'CONFIDENCE': min(10, combined_confidence + 1),  # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ ØªÙˆØ§ÙÙ‚
            'COMBINED_ANALYSIS': True,
            'MODELS_AGREE': True,
            'GEMINI_ANALYSIS': gemini_result.get('ANALYSIS', ''),
            'DEEPSEEK_ANALYSIS': deepseek_result.get('ANALYSIS', ''),
            'FINAL_ANALYSIS': f"ØªÙˆØ§ÙÙ‚ Ú©Ø§Ù…Ù„ Ø¨ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ - Ø³ÛŒÚ¯Ù†Ø§Ù„ {gemini_action} Ø¨Ø§ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨Ø§Ù„Ø§"
        }
    else:
        # ØªØ¶Ø§Ø¯ Ø¨ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ - Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø­ØªØ§Ø·Ø§Ù†Ù‡
        gemini_conf = gemini_result.get('CONFIDENCE', 5)
        deepseek_conf = deepseek_result.get('CONFIDENCE', 5)
        
        if abs(gemini_conf - deepseek_conf) >= 3:
            # Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ø¨Ø§ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨Ø§Ù„Ø§ØªØ±
            selected_result = gemini_result if gemini_conf > deepseek_conf else deepseek_result
            selected_model = 'Gemini' if gemini_conf > deepseek_conf else 'DeepSeek'
            
            selected_result['COMBINED_ANALYSIS'] = True
            selected_result['MODELS_AGREE'] = False
            selected_result['ANALYSIS'] = f"Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø§Ø² {selected_model} Ø¨Ø§ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨Ø§Ù„Ø§ØªØ± - Ù…Ø¯Ù„ Ø¯ÛŒÚ¯Ø± Ù…Ø®Ø§Ù„Ù Ø§Ø³Øª"
            return selected_result
        else:
            # Ø¹Ø¯Ù… Ù‚Ø·Ø¹ÛŒØª - HOLD
            return {
                'SYMBOL': symbol,
                'ACTION': 'HOLD',
                'CONFIDENCE': 0,
                'COMBINED_ANALYSIS': True,
                'MODELS_AGREE': False,
                'ANALYSIS': 'ØªØ¶Ø§Ø¯ Ø¨ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ - Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¨ÛŒØ´ØªØ±'
            }

class AdvancedForexAnalyzer:
    def __init__(self): 
        self.cache_manager = SmartCacheManager(CACHE_FILE, CACHE_DURATION_HOURS)
        self.technical_analyzer = AdvancedTechnicalAnalyzer()
        self.ai_manager = HybridAIManager(google_api_key, DEEPSEEK_API_KEY)

    async def analyze_pair(self, pair: str) -> Optional[Dict]:
        """ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ ÛŒÚ© Ø¬ÙØª Ø§Ø±Ø²"""
        if self.cache_manager.is_pair_on_cooldown(pair):
            return None
        
        logging.info(f"ğŸ” Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ {pair}")
        
        try:
            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±
            htf_df = await self.get_market_data_async(pair, HIGH_TIMEFRAME)
            ltf_df = await self.get_market_data_async(pair, LOW_TIMEFRAME)
            
            if htf_df is None or ltf_df is None:
                logging.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ {pair} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯")
                return None
            
            # ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
            htf_df = self.technical_analyzer.calculate_advanced_indicators(htf_df)
            ltf_df = self.technical_analyzer.calculate_advanced_indicators(ltf_df)
            
            if htf_df is None or ltf_df is None:
                logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ {pair}")
                return None
            
            technical_analysis = self.technical_analyzer.generate_technical_analysis(pair, htf_df, ltf_df)
            
            if not technical_analysis:
                logging.warning(f"ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø¨Ø±Ø§ÛŒ {pair} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")
                return None
            
            # ØªØ­Ù„ÛŒÙ„ ØªØ±Ú©ÛŒØ¨ÛŒ AI
            ai_analysis = await self.ai_manager.get_combined_analysis(pair, technical_analysis)
            
            if ai_analysis and ai_analysis.get('ACTION') != 'HOLD':
                self.cache_manager.update_cache(pair, ai_analysis)
                return ai_analysis
            else:
                logging.info(f"Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø¨Ø±Ø§ÛŒ {pair} Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯")
                return None
                
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ {pair}: {e}")
            return None

    async def get_market_data_async(self, symbol: str, interval: str, retries: int = 3) -> Optional[pd.DataFrame]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø¨Ù‡ ØµÙˆØ±Øª async"""
        for attempt in range(retries):
            try:
                url = f'https://api.twelvedata.com/time_series?symbol={symbol}&interval={interval}&outputsize={CANDLES_TO_FETCH}&apikey={TWELVEDATA_API_KEY}'
                
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, timeout=60) as response:
                        if response.status == 200:
                            data = await response.json()
                            if 'values' in data and len(data['values']) > 0:
                                df = pd.DataFrame(data['values'])
                                df = df.iloc[::-1].reset_index(drop=True)
                                
                                # ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†ÙˆØ§Ø¹ Ø¯Ø§Ø¯Ù‡
                                for col in ['open', 'high', 'low', 'close']:
                                    if col in df.columns:
                                        df[col] = pd.to_numeric(df[col], errors='coerce')
                                
                                df['datetime'] = pd.to_datetime(df['datetime'])
                                df.dropna(subset=['open', 'high', 'low', 'close'], inplace=True)
                                
                                return df
                        else:
                            logging.warning(f"Ø®Ø·Ø§ÛŒ HTTP {response.status} Ø¨Ø±Ø§ÛŒ {symbol}")
                            
            except Exception as e:
                logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol} (ØªÙ„Ø§Ø´ {attempt + 1}): {e}")
                await asyncio.sleep(2)
        
        return None

    async def analyze_all_pairs(self, pairs: List[str]) -> List[Dict]:
        """ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ù‡ Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…ÙˆØ§Ø²ÛŒ"""
        logging.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ {len(pairs)} Ø¬ÙØª Ø§Ø±Ø²")
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† concurrent tasks Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª rate limits
        semaphore = asyncio.Semaphore(1)  # Ø­Ø¯Ø§Ú©Ø«Ø± Û³ ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ø²Ù…Ø§Ù†
        
        async def bounded_analyze(pair):
            async with semaphore:
                result = await self.analyze_pair(pair)
                # ÛŒÚ© Ø«Ø§Ù†ÛŒÙ‡ ØªØ£Ø®ÛŒØ± Ø¨ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ù‡Ø± Ø¬ÙØªâ€ŒØ§Ø±Ø² Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ Ø³Ù‚Ù Ù…Ø­Ø¯ÙˆØ¯ÛŒØª API
                await asyncio.sleep(1)
                return result
        
        tasks = [bounded_analyze(pair) for pair in pairs]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬ Ù…ÙˆÙÙ‚
        valid_signals = []
        for result in results:
            if isinstance(result, Dict) and result.get('ACTION') != 'HOLD':
                valid_signals.append(result)
            elif isinstance(result, Exception):
                logging.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„: {result}")
        
        return valid_signals

async def main():
    # This entire block is now correctly indented
    logging.info("ğŸ¯ Ø´Ø±ÙˆØ¹ Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ ÙØ§Ø±Ú©Ø³ Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Hybrid AI v2.0)")
    analyzer = AdvancedForexAnalyzer()

    # Ø¨Ø±Ø±Ø³ÛŒ Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--pair", type=str, help="ØªØ­Ù„ÛŒÙ„ Ø¬ÙØª Ø§Ø±Ø² Ù…Ø´Ø®Øµ")
    parser.add_argument("--all", action="store_true", help="ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ù‡ Ø¬ÙØª Ø§Ø±Ø²Ù‡Ø§")
    args = parser.parse_args()

    if args.pair:
        pairs_to_analyze = [args.pair]
    elif args.all:
        pairs_to_analyze = CURRENCY_PAIRS_TO_ANALYZE
    else:
        # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†ÛŒ Ø¯Ø§Ø¯Ù‡ Ù†Ø´ÙˆØ¯ØŒ Ù‡Ù…Ù‡ Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†
        pairs_to_analyze = CURRENCY_PAIRS_TO_ANALYZE

    # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
    signals = await analyzer.analyze_all_pairs(pairs_to_analyze)

    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    if signals:
        output_file = "hybrid_ai_signals.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(signals, f, indent=4, ensure_ascii=False)
        
        logging.info(f"âœ… ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯. {len(signals)} Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¯Ø± {output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        
        # Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬
        for signal in signals:
            logging.info(f"ğŸ“ˆ {signal['SYMBOL']}: {signal['ACTION']} (Ø§Ø¹ØªÙ…Ø§Ø¯: {signal.get('CONFIDENCE', 'N/A')}/10)")
    else:
        logging.info("ğŸ” Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒâ€ŒØ§ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ø§Ø¬Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯")

    logging.info("ğŸ Ù¾Ø§ÛŒØ§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…")

if __name__ == "__main__":
    asyncio.run(main())
